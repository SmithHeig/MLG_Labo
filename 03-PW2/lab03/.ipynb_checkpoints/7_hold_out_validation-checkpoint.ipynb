{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold-out validation\n",
    "In hold-out validation the dataset is split in two parts: one part is used during training and the other is used for testing the generalization capabilities of the model. This method has the advantage of being easy to implement. However, in hold-out validation the generalisation performance is evaluated with a single test, using a dataset partition that not necessarily represents the whole distribution of the whole dataset. Hence, it can produce some undesirable behaviours that lead to a wrong assessment of the performance of the model. In this notebook you are going to explore the behaviour of hold-out validation by simulating datasets with diverse degrees of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sys\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "This function creates a dataset with two classes in two dimensions. It has two parameters: the size of the dataset and the spread of each one of the classes. A high spread value makes both classes to superpose, making the classification more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(n, s):\n",
    "    n1 = int(np.ceil(n / 2.0))\n",
    "    n2 = int(np.floor(n / 2.0))\n",
    "    x1 = np.random.normal(-1, s, n1)\n",
    "    y1 = np.random.uniform(-1, 1,  n1)\n",
    "    x2 = np.random.normal(1, s, n2)\n",
    "    y2 = np.random.uniform(-1, 1, n2)\n",
    "    return np.stack((np.concatenate((x1, x2)), np.concatenate((y1, y2)), np.concatenate((np.ones(n1), -1*np.ones(n2)))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dataset(s):\n",
    "    dataset = create_dataset(200, s)\n",
    "    pl.scatter(dataset[:,0], dataset[:,1], c=[(['b', 'r'])[int(cl > 0)] for cl in dataset[:,2]])\n",
    "    pl.xlim(-3,3)\n",
    "    pl.ylim(-1,1)\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interact(plot_dataset, s=widgets.FloatSlider(value=0.1, min=0.1, max=1.0, step=0.01, description='Spread:',));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mlp_backprop_momentum as mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring hold-out validation\n",
    "The following function splits the dataset in two parts. The parameter `train_test_ratio` controls the proportions of the partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_test_ratio = 0.8):\n",
    "    index_all = np.arange(dataset.shape[0])\n",
    "    np.random.shuffle(index_all)\n",
    "    break_point = int(train_test_ratio * len(index_all))\n",
    "    index_train = index_all[0:break_point]\n",
    "    index_test = index_all[break_point:]\n",
    "    dataset_train = dataset[index_train,:]\n",
    "    dataset_test = dataset[index_test,:]\n",
    "    return (dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "In this experiment we create datasets with different degrees of complexity and we test the behaviour of hold-out validation with each one of them. For each dataset, we split the dataset several times, which generates different partitions training/testing. We also initializes the neural networks several times with each partition in order to be sure that the results are not a special case of a lucky initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_INITS = 2\n",
    "N_SPLITS = 10\n",
    "DATASET_SIZE = 200\n",
    "EPOCHS = 100\n",
    "N_NEURONS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.7\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "DATA_PARAMS = np.arange(0.4, 0.71, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS, EPOCHS))\n",
    "MSE_test = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS, EPOCHS))\n",
    "MSE_test_last = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS))\n",
    "for p, s in enumerate(DATA_PARAMS):                                     # looping the set of parameters\n",
    "    print('Testing dataset with variance:', s)\n",
    "\n",
    "    dataset = create_dataset(DATASET_SIZE, s)\n",
    "    \n",
    "    for d in np.arange(N_SPLITS):                                       # looping the splits\n",
    "        dataset_train, dataset_test = split_dataset(dataset, TRAIN_TEST_RATIO)\n",
    "    \n",
    "        for i in np.arange(N_INITS):                                    # looping the initializations\n",
    "            sys.stdout.write('.')\n",
    "            nn = mlp.MLP([2,N_NEURONS,1], 'tanh')\n",
    "            input_data = dataset_train[:,0:nn.n_inputs]\n",
    "            output_data = dataset_train[:,nn.n_inputs:(nn.n_inputs+nn.n_outputs)]\n",
    "            input_data_test = dataset_test[:,0:nn.n_inputs]\n",
    "            output_data_test = dataset_test[:,nn.n_inputs:(nn.n_inputs+nn.n_outputs)]\n",
    "\n",
    "            t = (d * N_INITS) + i\n",
    "            MSE_train[p,t,:], MSE_test[p,t,:] = nn.fit((input_data, output_data), \n",
    "                                                       (input_data_test, output_data_test),\n",
    "                                                       learning_rate=LEARNING_RATE, momentum=MOMENTUM, epochs=EPOCHS)\n",
    "            MSE_test_last[p,t] = MSE_test[p,t,-1]\n",
    "    print(N_INITS * N_SPLITS, 'tests done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting MSE, we can observe that each partition, i.e., each run of hold-out validation, generates different values of model error. For the same dataset, running hold-out validation several times does not generate coherent assessments of model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_COL = 4\n",
    "n_rows = np.ceil(float(MSE_train.shape[0]) / MAX_COL)\n",
    "pl.figure(figsize=(12, 4 * n_rows))\n",
    "for d in range(MSE_train.shape[0]):\n",
    "    pl.subplot(n_rows, MAX_COL, d+1)\n",
    "    for r in range(MSE_train.shape[1]):\n",
    "        pl.plot(MSE_train[d,r,:], c='c', label='Training')\n",
    "        pl.plot(MSE_test[d,r,:], c='r', label='Testing')\n",
    "        if d == 0 and r == 0:\n",
    "            pl.legend()\n",
    "    pl.ylim(0, 0.6)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Iteration')\n",
    "    pl.title('Spread: '+str(DATA_PARAMS[d]))\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the red curves end (last iteration) at different values of MSE. Different partitions are more or less easy to learn. Some data partitions are memorized by the neural networ: which means a low training error and a high testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.boxplot(MSE_test_last.T, positions=DATA_PARAMS, widths=0.05)\n",
    "for c in np.arange(MSE_test_last.shape[1]):\n",
    "    pl.scatter(DATA_PARAMS, MSE_test_last[:,c], s=10, c='g', marker='x')\n",
    "\n",
    "pl.xlim(np.min(DATA_PARAMS)-0.1, np.max(DATA_PARAMS)+0.1)\n",
    "pl.xlabel('Spread')\n",
    "pl.ylabel('MSE')\n",
    "pl.title('Several runs of hold-out validation')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {
    "be367bcade124b30aeaf8724d3ffbbe4": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
